{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "In this notebook, we are exploring the dataset used for the vehicle localization assigment. The provided files are in the Point Cloud Data (PCD) format, which are crucial for processing and visualizing spatial data in autonomous vehicle technology.\n",
    "\n",
    "## Files Included\n",
    "\n",
    "- **map.pcd:** This file represents the map where the vehicle needs to localize itself.\n",
    "- **frames/frames_\\<n\\>.pcd:** This directory contains sequential frames from 0 to 1013, capturing different moments and perspectives of the vehicle's journey inside the CARLA simulator.\n",
    "- **ground_truth:** This file contains the exact vehicle positions in meters and orientations in radians for each frame from 0 to 1013. It serves as a reference to evaluate the vehicle's localization accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ground truth values\n",
    "\n",
    "To handle and visualize the ground truth data efficiently, we will use various Python libraries. These libraries will help in loading, processing, and plotting the data for better analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "\n",
    "from pypcd4 import PointCloud\n",
    "from scipy.spatial.transform import Rotation\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "# Load ground truths\n",
    "gts = pd.read_csv(\"./dataset/ground_truth.csv\")\n",
    "\n",
    "# Print gt\n",
    "print(gts)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily retrieve the vehicle's position and orientation using pandas with the following approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "source": [
    "\n",
    "# Get position and orientation for a specific frame\n",
    "FRAME = 50\n",
    "gt = gts.iloc[FRAME]\n",
    "\n",
    "# Extract the row and use direct slicing to create numpy arrays\n",
    "gt = gts.iloc[FRAME]\n",
    "pos = gt[['x', 'y', 'z']].to_numpy()\n",
    "orientation = gt[['roll', 'pitch', 'yaw']].to_numpy()\n",
    "\n",
    "# Print position and orientation arrays\n",
    "print(f\"Position: {pos}\")\n",
    "print(f\"Orientation: {orientation}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate error\n",
    "\n",
    "For this assigment you need to calculate the error between the localization and the ground truth values. You can calculate two types of errors by comparing the ground truth data with estimated values:\n",
    "\n",
    "1. **Lateral Error**: Measures the deviation between the ground truth and estimated positions in the XY plane.\n",
    "   \n",
    "2. **Yaw Angle Error**: Determines the difference between the ground truth and estimated orientations in the yaw angle.\n",
    "\n",
    "The following function computes these errors given ground truth and estimated positions/orientations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "source": [
    "def calc_error(gt_position: np.ndarray, gt_orientation: List[float], estimated_position: np.ndarray, estimated_orientation: np.ndarray) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Calculates lateral error and yaw angle error based on ground truth and estimated values.\n",
    "\n",
    "    Args:\n",
    "    - gt_position (np.ndarray): Ground truth displacements in [x, y, z] format.\n",
    "    - gt_orientation (List[float]): Ground truth angles in [roll, pitch, yaw] format.\n",
    "    - estimated_position (np.ndarray): Estimated displacements in [x, y, z] format.\n",
    "    - estimated_orientation (np.ndarray): Estimated angles in [roll, pitch, yaw] format.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[float, float]: Lateral error in meters and yaw angle error in degrees.\n",
    "    \"\"\"\n",
    "    if not (gt_position.shape == (3,) and estimated_position.shape == (3,)):\n",
    "        raise ValueError(\"Position inputs should be 1D numpy arrays with 3 elements [x, y, z].\")\n",
    "\n",
    "    if not (len(gt_orientation) == 3 and len(estimated_orientation) == 3):\n",
    "        raise ValueError(\"Orientation inputs should be a list of 3 elements [roll, pitch, yaw] and a 3x3 rotation matrix.\")\n",
    "\n",
    "    # Calculate lateral error in the XY plane\n",
    "    position_error = np.linalg.norm(estimated_position[:2] - gt_position[:2])\n",
    "\n",
    "    # Calculate yaw angle error in degrees\n",
    "    yaw_error = gt_orientation[2] - estimated_orientation[2]\n",
    "\n",
    "    return position_error, yaw_error\n",
    "\n",
    "\n",
    "# Sim estimations\n",
    "t_estimated = np.array([[10],\n",
    "              [5],\n",
    "              [0]])\n",
    "\n",
    "yaw = 45\n",
    "R_estimated = Rotation.from_euler(\"z\", yaw, degrees=True).as_matrix() \n",
    "\n",
    "# Transform to position and orientation\n",
    "estimated_pos = t_estimated.flatten()\n",
    "estimated_orientation = Rotation.from_matrix(R_estimated).as_euler(\"xyz\")\n",
    "\n",
    "# Calculate errors\n",
    "\n",
    "pos_error, yaw_error = calc_error(pos, orientation, estimated_pos, estimated_orientation)\n",
    "\n",
    "# Print position and orientation arrays\n",
    "print(f\"GT Position: {pos}\")\n",
    "print(f\"GT Orientation: {orientation}\\n\")\n",
    "\n",
    "print(f\"Estimated Position: {estimated_pos}\")\n",
    "print(f\"Estimated Orientation: {estimated_orientation}\\n\")\n",
    "\n",
    "print(f\"Position Error: {pos_error}\")\n",
    "print(f\"Position Error: {yaw_error}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with PCD files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will also work with point clouds representing 3D environments. This section provides useful resources for processing these point clouds effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PCD files\n",
    "\n",
    "As explored in the Sensor Fusion assignment, one of the primary formats for storing point cloud data is the PCD (Point Cloud Data) format. The dataset for this project contains files exclusively in this format, so we'll need to load these files into our programs efficiently.\n",
    "\n",
    "For this purpose, we'll use the `pypcd4` library and create a custom function to load point cloud data (PCDs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "def pcd_from_path(file_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Loads point clouds from PCD files using the PointCloud library (assumed to be open3d or similar).\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to a .pcd file.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Numpy array representing the point cloud, shape [n_points, m_channels].\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the file format is not 'pcd'.\n",
    "        FileNotFoundError: If the file does not exist.\n",
    "    \"\"\"\n",
    "    if not file_path.endswith(\".pcd\"):\n",
    "        raise ValueError('Only \".pcd\" format is accepted.')\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
    "    \n",
    "    pc = PointCloud.from_path(file_path)\n",
    "    return pc.numpy()\n",
    "\n",
    "\n",
    "# Load the map and frame data as point clouds\n",
    "map_array = pcd_from_path(\"./dataset/map.pcd\") \n",
    "pointcloud_array = pcd_from_path(\"./dataset/frames/frame_0.pcd\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing PCD Data\n",
    "\n",
    "Visualizing point cloud data is crucial for understanding the spatial relationships and structures within the data, which is particularly important in applications such as autonomous vehicle navigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Visualization of Point Clouds\n",
    "\n",
    "Iniatlly, it's often useful to represent point cloud data in a 2D plot. This can help in quickly analyzing the data's general spatial distribution and provide an easily interpretable visualization for debugging or exploring specific regions. The following function demonstrates how to plot point cloud data in 2D using Matplotlib. As you can see we are ploting the data from a Bird Eye View perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "source": [
    "def plot_pcd(ax: plt.Axes, points: np.ndarray, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots point cloud data on a given matplotlib axis.\n",
    "\n",
    "    Parameters:\n",
    "        ax (matplotlib.axes.Axes): The axes on which to plot the point cloud.\n",
    "        points (np.ndarray): The point cloud data, expected shape [n_points, at least 2].\n",
    "        **kwargs: Additional keyword arguments passed to matplotlib scatter plot.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If 'points' does not have the correct dimensions.\n",
    "    \"\"\"\n",
    "    if points.ndim < 2 or points.shape[1] < 2:\n",
    "        raise ValueError(\"The 'points' array must have at least two dimensions [n_points, at least 2].\")\n",
    "\n",
    "    return ax.scatter(points[:, 0], points[:, 1], **kwargs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "source": [
    "fig, (ax1,ax2) = plt.subplots(2,1)\n",
    "\n",
    "plot_pcd(ax1, map_array, color=\"red\", label=\"Target\", marker='x',s=.10)\n",
    "plot_pcd(ax2, pointcloud_array, color=\"blue\", label=\"Source\", marker='x',s=.10)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D Visualization of Point Clouds\n",
    "\n",
    "To effectively analyze the 3D structure of the environment captured in PCD files, we'll use a Python function to render the point clouds in a 3D space. This visualization helps to have a grasp on how the pointcloud is structured. For this we will rely on the `open3d` library that has several tools to work with pointclouds in python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "source": [
    "def show_pcl(pcl: np.ndarray):\n",
    "    \n",
    "    pointcloud = o3d.geometry.PointCloud()\n",
    "    pointcloud.points = o3d.utility.Vector3dVector(pcl[:,:3])\n",
    "\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pointcloud)\n",
    "    \n",
    "    opt = vis.get_render_option()\n",
    "    opt.background_color = (0, 0, 0)\n",
    "    opt.point_size = 2\n",
    "\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "    del opt  # Delete to avoid having  [Open3D ERROR] GLFW Error: The GLFW library is not initialized\n",
    "    del vis  # Delete to avoid having  [Open3D ERROR] GLFW Error: The GLFW library is not initialized"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "# Example of how to visualize the map and a frame\n",
    "#### Map Visualization\n",
    "show_pcl(map_array)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "#### Frame Visualization\n",
    "show_pcl(pointcloud_array)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample poincloud\n",
    "\n",
    "When analyzing the map and frame point clouds, it's evident that these data arrays consist of an immense number of individual points. This high density can significantly increase computation time and lead to unstable results during processing. To address these challenges, downsampling is an essential step in point cloud processing that aims to reduce the density of the points while maintaining the overall structural integrity.\n",
    "\n",
    "#### Importance of Downsampling:\n",
    "\n",
    "1. **Improved Computation Time:** High-density point clouds are computationally intensive, especially in tasks like registration (aligning point clouds). Downsampling simplifies the data, leading to faster processing.\n",
    "\n",
    "2. **Stability in Analysis:** Excessive points may introduce noise and outliers into the data, resulting in inconsistent results. Downsampling can help filter out these unwanted elements, providing a more stable dataset for further analysis.\n",
    "\n",
    "3. **Memory Efficiency:** Reducing point density lowers memory usage, making it feasible to handle larger datasets without overwhelming available system resources.\n",
    "\n",
    "#### Voxelization\n",
    "\n",
    "A particularly effective technique for downsampling is voxelization. This method involves dividing the 3D space into a grid of small, cube-like cells known as voxels. Each voxel represents several nearby points, reducing the overall count while preserving spatial relationships The key benefits of voxelization include:\n",
    "\n",
    "1. **Reduced Data Size:** Each voxel represents multiple nearby points, effectively reducing the overall number of data points.\n",
    "2. **Spatial Structure Retention:** Despite the reduction in data, the voxel grid preserves the original spatial relationships and geometries within the point cloud.\n",
    "\n",
    "The following code demonstrates how to downsample a point cloud using `open3d`'s voxel grid utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "source": [
    "\n",
    "def downsample_voxel(map_array: np.ndarray, voxel_size: float):\n",
    "    \"\"\"\n",
    "    Downsamples a pointcloud using a voxel grid, and provides voxel configurations.\n",
    "\n",
    "    Args:\n",
    "    - map_pcd_arr (np.ndarray): Input point cloud as an Nx3 numpy array.\n",
    "    - voxel_size (float): Desired voxel size for downsampling.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[np.ndarray, dict]: Downsampled point cloud as an Nx3 numpy array,\n",
    "                               and a dictionary with voxel configuration details.\n",
    "    \"\"\"\n",
    "    # Convert np array to open3D pointcloud\n",
    "    map_pcd = o3d.geometry.PointCloud()\n",
    "    map_pcd.points = o3d.utility.Vector3dVector(map_array)\n",
    "    \n",
    "    # Use open3D voxelisation utility with desired voxel_size\n",
    "    voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(map_pcd, voxel_size)\n",
    "    \n",
    "    # Get coordinates of the voxels that are points of the downsampled grid\n",
    "    indices = np.array([voxel.grid_index for voxel in voxel_grid.get_voxels()], dtype=float) * voxel_size\n",
    "\n",
    "    # Calculate voxel configuration details\n",
    "    max_bound = voxel_grid.get_max_bound()\n",
    "    min_bound = voxel_grid.get_min_bound()\n",
    "    voxel_config = {\n",
    "        'voxel_bounds': {'min': 0, 'max': indices.max(axis=0)},\n",
    "        'real_bounds': {'min': min_bound, 'max': max_bound}\n",
    "    }\n",
    "\n",
    "    # Adjust indices to represent real-world coordinates (center of each voxel)\n",
    "    indices += min_bound + voxel_size / 2\n",
    "\n",
    "    return indices, voxel_config\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the effects of downsampling the map at different voxel sizes. We will compare the original map with maps downsampled using two voxel sizes: `0.5` and `0.25`. This will illustrate how voxelization can reduce point cloud density while preserving spatial information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "voxel_size = 0.5\n",
    "\n",
    "# Downsample the point cloud for different purposes\n",
    "voxel_map_0_5, voxel_config_show = downsample_voxel(map_array, voxel_size=voxel_size)  # Better for plotting purposes\n",
    "voxel_map_0_25, voxel_config = downsample_voxel(map_array, voxel_size=voxel_size / 2)  # Good for ICP\n",
    "\n",
    "# Print sizes of the original and downsampled point clouds\n",
    "print(\"Point Cloud Sizes:\")\n",
    "print(f\"Original shape = {map_array.shape}\")\n",
    "print(f\"Voxel size = {voxel_size / 2} -> Downsampled shape = {voxel_map_0_25.shape}\")\n",
    "print(f\"Voxel size = {voxel_size} -> Downsampled shape = {voxel_map_0_5.shape}\")\n",
    "\n",
    "# Plot the original and downsampled maps\n",
    "fig, axs = plt.subplots(3, 1, figsize=(8, 16))\n",
    "\n",
    "# Plot the original map\n",
    "axs[0].set_title(\"Original Map\")\n",
    "plot_pcd(axs[0], map_array, color=\"red\", label=\"Original\", marker='x', s=0.10)\n",
    "\n",
    "# Plot the map downsampled at voxel_size/2\n",
    "axs[1].set_title(f\"Downsampled Map (Voxel Size = {voxel_size / 2})\")\n",
    "plot_pcd(axs[1], voxel_map_0_25, color=\"green\", label=\"Downsampled (0.25)\", marker='x', s=0.10)\n",
    "\n",
    "# Plot the map downsampled at voxel_size\n",
    "axs[2].set_title(f\"Downsampled Map (Voxel Size = {voxel_size})\")\n",
    "plot_pcd(axs[2], voxel_map_0_5, color=\"blue\", label=\"Downsampled (0.5)\", marker='x', s=0.10)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's examine the effects of downsampling the frame at different voxel sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "source": [
    "voxel_size = 0.5\n",
    "\n",
    "# Downsample the point cloud for different purposes\n",
    "voxel_frame_0_5, voxel_config_show = downsample_voxel(pointcloud_array, voxel_size=voxel_size)  # Better for plotting purposes\n",
    "voxel_frame_0_25, voxel_config = downsample_voxel(pointcloud_array, voxel_size=voxel_size / 2)  # Good for ICP\n",
    "\n",
    "# Print sizes of the original and downsampled point clouds\n",
    "print(\"Point Cloud Sizes:\")\n",
    "print(f\"Original shape = {map_array.shape}\")\n",
    "print(f\"Voxel size = {voxel_size / 2} -> Downsampled shape = {voxel_map_0_25.shape}\")\n",
    "print(f\"Voxel size = {voxel_size} -> Downsampled shape = {voxel_map_0_5.shape}\")\n",
    "\n",
    "# Plot the original and downsampled maps\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# Plot the original map\n",
    "axs[0].set_title(\"Original Frame\")\n",
    "plot_pcd(axs[0], pointcloud_array, color=\"red\", label=\"Original\", marker='x', s=0.10)\n",
    "\n",
    "# Plot the map downsampled at voxel_size/2\n",
    "axs[1].set_title(f\"Downsampled Frame (Voxel Size = {voxel_size / 2})\")\n",
    "plot_pcd(axs[1], voxel_frame_0_25, color=\"green\", label=\"Downsampled (0.25)\", marker='x', s=0.10)\n",
    "\n",
    "# Plot the map downsampled at voxel_size\n",
    "axs[2].set_title(f\"Downsampled Frame (Voxel Size = {voxel_size})\")\n",
    "plot_pcd(axs[2], voxel_frame_0_5, color=\"blue\", label=\"Downsampled (0.5)\", marker='x', s=0.10)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symplifying further the poincloud to retain only boundaries\n",
    "\n",
    "In general, the NDT (Normal Distributions Transform) algorithm presented in [Example](../Examples/NDT_localization.ipynb) is designed for 2D localization, as the calculated Jacobians and Hessians assume a **2D** space. The grids used are also 2D, leading to distributions suitable for two-dimensional mapping. However, similar derivations can be applied to achieve the equations required for a **3D** space.\n",
    "\n",
    "A beneficial approach to improve the efficiency of both NDT and ICP is to simplify point clouds by retaining only their boundaries. This can be achieved using `open3d` to extract boundaries from the point clouds, as shown in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "source": [
    "def boundaries(map_array: np.ndarray, r: float = 2.5, n_iter: int = 2000, zlims: Tuple[float, float] = (-1, 7), device_str: str = \"CPU:0\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Detects boundaries in a voxelized point cloud and trims the results within specified z-limits.\n",
    "\n",
    "    Args:\n",
    "    - map_array (np.ndarray): Voxelized point cloud, shape (Nr_points, 3).\n",
    "    - r (float): Radius to consider points as part of the same object.\n",
    "    - n_iter (int): Number of iterations for edge detection.\n",
    "    - zlims (Tuple[float, float]): Minimum and maximum z-values to consider.\n",
    "    - device_str (str): Device identifier for computation.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Point cloud containing detected boundaries, shape (Nr_points_downsampled, 3).\n",
    "    \"\"\"\n",
    "    # Set up the computation device and data type\n",
    "    device = o3d.core.Device(device_str)\n",
    "    dtype = o3d.core.Dtype.Float32\n",
    "\n",
    "    # Initialize an empty point cloud on the specified device\n",
    "    tensor_map = o3d.t.geometry.PointCloud(device)\n",
    "\n",
    "    # Assign data to point cloud\n",
    "    tensor_map.point['positions'] = o3d.core.Tensor(map_array, dtype, device)\n",
    "\n",
    "    # Estimate normals for the point cloud\n",
    "    tensor_map.estimate_normals()\n",
    "\n",
    "    # Calculate the boundaries of the point cloud using the provided radius and iterations\n",
    "    boundaries, _ = tensor_map.compute_boundary_points(r, n_iter)\n",
    "\n",
    "    # Extract the boundary points as a NumPy array\n",
    "    np_boundaries = boundaries.point['positions'].numpy()\n",
    "\n",
    "    # Apply z-limits to filter the point cloud\n",
    "    z_filter = (np_boundaries[:, 2] > zlims[0]) & (np_boundaries[:, 2] < zlims[1])\n",
    "    np_boundaries = np_boundaries[z_filter]\n",
    "\n",
    "    return np_boundaries"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example for Map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "source": [
    "voxel_size = 0.25\n",
    "r = 2.5\n",
    "zlims = [0, 7]\n",
    "\n",
    "# Downsample the point cloud for plotting purposes\n",
    "voxel_map, voxel_config_show = downsample_voxel(map_array, voxel_size=voxel_size)\n",
    "\n",
    "# Filter to create a boundary-reduced map\n",
    "bounded_map = boundaries(voxel_map, r=r, zlims=zlims)\n",
    "\n",
    "# Plot both the downsampled and boundary-reduced maps\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "\n",
    "# Plot the downsampled map\n",
    "ax1.set_title(\"Downsampled Point Cloud\")\n",
    "plot_pcd(ax1, voxel_map, color=\"blue\", label=\"Downsampled Map\", marker='x', s=0.10)\n",
    "ax1.set_ylabel(\"Y [m]\")\n",
    "ax1.set_xlabel(\"X [m]\")\n",
    "ax1.grid()\n",
    "\n",
    "# Plot the boundary-reduced map\n",
    "ax2.set_title(\"Boundary-Reduced Point Cloud\")\n",
    "plot_pcd(ax2, bounded_map, color=\"red\", label=\"Boundary-Reduced Map\", marker='x', s=0.10)\n",
    "ax2.set_ylabel(\"Y [m]\")\n",
    "ax2.set_xlabel(\"X [m]\")\n",
    "ax2.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example for frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "source": [
    "voxel_size = 0.25\n",
    "r = 2.5\n",
    "zlims = [0, 7]\n",
    "\n",
    "# Downsample the point cloud for plotting purposes\n",
    "voxel_frame, voxel_config_show = downsample_voxel(pointcloud_array, voxel_size=voxel_size)\n",
    "\n",
    "# Filter to create a boundary-reduced map\n",
    "bounded_frame = boundaries(voxel_frame, r=r, zlims=zlims)\n",
    "\n",
    "# Plot both the downsampled and boundary-reduced maps\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "\n",
    "# Plot the downsampled map\n",
    "ax1.set_title(\"Downsampled Point Cloud\")\n",
    "plot_pcd(ax1, voxel_frame, color=\"blue\", label=\"Downsampled Frame\", marker='x', s=0.10)\n",
    "ax1.set_ylabel(\"Y [m]\")\n",
    "ax1.set_xlabel(\"X [m]\")\n",
    "ax1.grid()\n",
    "\n",
    "# Plot the boundary-reduced map\n",
    "ax2.set_title(\"Boundary-Reduced Point Cloud\")\n",
    "plot_pcd(ax2, bounded_frame, color=\"red\", label=\"Boundary-Reduced Frame\", marker='x', s=0.10)\n",
    "ax2.set_ylabel(\"Y [m]\")\n",
    "ax2.set_xlabel(\"X [m]\")\n",
    "ax2.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further simplifications\n",
    "\n",
    "If you're encountering challenges with the NDT algorithm, here are some practical suggestions to consider, especially if you aim to use the 2D formulation:\n",
    "\n",
    "1. **Convert the Map and frame to 2D:** Since the vehicle primarily moves on a flat road, you can simplify the point cloud data by working in 2D. Ground truth data indicates that variations in the z-coordinate, roll, and pitch are minimal. Thus, you can:\n",
    "\n",
    "    - **Filter Ground Points:** Remove points representing the road surface since they contribute little unique mapping information.\n",
    "    - **Limit Maximum Height:** Set a reasonable height limit to focus on features relevant to the vehicle's navigation.\n",
    "    - **Use X and Y Coordinates Only:** For both the map and frame, retain only the X and Y coordinates, setting the z-coordinate to zero.\n",
    "\n",
    "By reducing the data to a 2D map, the NDT algorithm becomes more computationally efficient and easier to handle. Additionally, this simplification helps to identify relevant landmarks for accurate localization, making the process more robust and reliable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "localization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
