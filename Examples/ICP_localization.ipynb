{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Closest Point Localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview \n",
    "\n",
    "The Iterative Closest Point (ICP) algorithm is a localization algorithm primarily used in the fields of computer vision and robotics to align or register two point clouds. This is crucial in a variety of applications such as 3D reconstruction, object recognition, and autonomous navigation, where precise alignment of different scans of an environment is necessary.\n",
    "\n",
    "The ICP algorithm is designed to minimize the difference between two clouds of points (source and target) by finding the best rigid transformation (rotation and translation) that aligns the source point cloud to the target point cloud. The algorithm assumes that the two point clouds are approximately aligned and iteratively refines the transformation to enhance the alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Foundations of ICP\n",
    "\n",
    "Following the overview where the Iterative Closest Point (ICP) algorithm was introduced for aligning two point clouds, we delve into the mathematical formulations that constitute this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    " Given two sets of points:\n",
    "\n",
    "1. $P = {p_1, \\cdots, p_N}$ - Source Points\n",
    "2. $Q = {q_1, \\cdots, q_N}$ - Target Points\n",
    "\n",
    "With centroids:\n",
    "\n",
    "1. $\\mu_P = \\frac{1}{N} \\sum_{i=1}^N p_i$ - Centroid of the source points \n",
    "2. $\\mu_Q = \\frac{1}{N} \\sum_{i=1}^N q_i$ - Centroid of the target points\n",
    "\n",
    "The objective of the ICP algorithm is to discover the rigid transformation, consisting of a rotation matrix $R$ and a translation vector $t$, that minimizes the error when applied to the source points $P$\n",
    "\n",
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "import tools.utils as utils \n",
    "\n",
    "\n",
    "def calculate_centroid(points: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the centroid of a set of points.\n",
    "\n",
    "    Parameters:\n",
    "        points (np.ndarray): An array of points of shape (n_points, 3).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The centroid of the points.\n",
    "    \"\"\"\n",
    "    return np.mean(points, axis=0)\n",
    "\n",
    "\n",
    "# Load points\n",
    "P = utils.pcd_from_path(\"./dataset/source.pcd\") # Source points\n",
    "Q = utils.pcd_from_path(\"./dataset/target.pcd\") # Target points\n",
    "\n",
    "# Calculate centroids\n",
    "centroid_P = calculate_centroid(P)\n",
    "centroid_Q = calculate_centroid(Q)\n",
    "\n",
    "# Plotting the original and transformed point cloud\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(P[:,0], P[:,1], color='red', alpha=0.5, label='Source Points')\n",
    "plt.scatter(Q[:,0], Q[:,1], color='green', alpha=0.5, label='Target Points')\n",
    "plt.scatter(centroid_P[0], centroid_P[1], color='darkred', marker='x', s=100, label='Source Centroid')\n",
    "plt.scatter(centroid_Q[0], centroid_Q[1], color='darkgreen', marker='x', s=100, label='Target Centroid')\n",
    "plt.xlabel('X coordinate')\n",
    "plt.ylabel('Y coordinate')\n",
    "plt.title('Point Cloud Visualization with Centroids')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Rigid Transformation Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A rigid transformation is a mathematical operation applied to data to transition from one coordinate system to another, involving only rotation RR and translation tt. This operation is formally defined as:\n",
    "\n",
    "$$\n",
    "P' = RP+t\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $P$ represents the source points.\n",
    "- $P'$ represents the transformed points.\n",
    "- $R$ is the rotation matrix that rotates each point around the origin.\n",
    "- $t$ is the translation vector that uniformly shifts all points.\n",
    "\n",
    "\n",
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "source": [
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "def rigid_transformation(cloud: np.ndarray, R: np.ndarray, t: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Applies a rigid transformation to a point cloud.\n",
    "    \n",
    "    Parameters:\n",
    "        cloud (np.ndarray): A point cloud array of shape (n_points, 3).\n",
    "        R (np.ndarray): Rotation matrix of shape (3, 3).\n",
    "        t (np.ndarray): Translation vector of shape (3, 1).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Transformed point cloud of shape (n_points, 3).\n",
    "    \"\"\"\n",
    "    # Validate input types\n",
    "    if not isinstance(cloud, np.ndarray):\n",
    "        raise TypeError(\"The point cloud must be a numpy array.\")\n",
    "    if not isinstance(R, np.ndarray):\n",
    "        raise TypeError(\"The rotation matrix must be a numpy array.\")\n",
    "    if not isinstance(t, np.ndarray):\n",
    "        raise TypeError(\"The translation vector must be a numpy array.\")\n",
    "\n",
    "    # Validate input dimensions\n",
    "    if cloud.ndim != 2 or cloud.shape[1] != 3:\n",
    "        raise ValueError(\"Point cloud shape must be (n_points, 3).\")\n",
    "    if R.shape != (3, 3):\n",
    "        raise ValueError(\"Rotation matrix must have shape (3, 3).\")\n",
    "    if t.shape != (3, 1):\n",
    "        raise ValueError(\"Translation vector must have shape (3, 1).\")\n",
    "\n",
    "    # Validate matrix compatibility\n",
    "    if cloud.shape[1] != R.shape[0]:\n",
    "        raise ValueError(\"The number of columns in the point cloud must match the number of rows in the rotation matrix.\")\n",
    "    \n",
    "    return (R @ cloud.T + t).T\n",
    "\n",
    "# Create rigid transformation parameters\n",
    "t = np.array([[10], [5], [0]])  # Translation vector\n",
    "\n",
    "# Rotation matrix using Roll, Pitch, Yaw (only yaw is non-zero for 2D rotation around Z)\n",
    "yaw = 45  # 45 degrees over z axis\n",
    "R = Rotation.from_euler('z', yaw, degrees=True).as_matrix()\n",
    "\n",
    "# Load points from a file\n",
    "P = utils.pcd_from_path(\"./dataset/arrow.pcd\")\n",
    "\n",
    "# Apply transformation\n",
    "Q = rigid_transformation(P, R, t)\n",
    "\n",
    "# Calculate centroids\n",
    "centroid_P = calculate_centroid(P)\n",
    "centroid_Q = calculate_centroid(Q)\n",
    "\n",
    "# Plotting the original and transformed point cloud\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(P[:,0], P[:,1], color='red', alpha=0.5, label='Source Points')\n",
    "plt.scatter(Q[:,0], Q[:,1], color='green', alpha=0.5, label='Target Points')\n",
    "plt.scatter(centroid_P[0], centroid_P[1], color='darkred', marker='x', s=100, label='Source Centroid')\n",
    "plt.scatter(centroid_Q[0], centroid_Q[1], color='darkgreen', marker='x', s=100, label='Target Centroid')\n",
    "plt.xlabel('X coordinate')\n",
    "plt.ylabel('Y coordinate')\n",
    "plt.title('Rigid Transformation')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Square Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously discussed, the core objective of the ICP algorithm is to find the rotation matrix $R$ and translation vector $t$ that minimize the error between the transformed source points $P'$ and the target points $Q$. This objective is achieved through least squares optimization, which quantifies the error using the least squares error metric. The error is formally defined as:\n",
    "\n",
    "$$\n",
    "E =  \\frac{1}{N}\\sum_{i=1}^N  || q_i - p'_i ||^2\n",
    "$$\n",
    "\n",
    "Where $p'_i=Rp_i+t​$ for each point $p_i$ in the source set $P$, leading to the expression:\n",
    "\n",
    "$$\n",
    "E(R,t) = \\frac{1}{N}\\sum_{i=1}^N  || q_i - (Rp_i + t)||^2\n",
    "$$\n",
    "\n",
    "To solve this problem, the ICP algorithm employs an optimization strategy that seeks to minimize this error function, expressed as:\n",
    "\n",
    "$$\n",
    "\\operatorname*{arg\\,min}_{R,t} \\frac{1}{N}\\sum_{i=1}^N  || q_i - Rp_i - t||^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Value Decomposition (SVD) Optimization\n",
    "\n",
    "To address the problem of finding the optimal rotation matrix $R$ and translation vector $t$, we employ an optimization strategy based on Singular Value Decomposition (SVD). This method requires a prior understanding of the correspondences between points in sets $P$ and $Q$, specifically knowing which pairs of indices $i$ and $j$ correspond such that:\n",
    "\n",
    "$$p_i \\rightarrow q_j$$\n",
    "\n",
    "#### Solving for t\n",
    "\n",
    "Assuming $R$ is fixed, we first focus on optimizing $t$. For this, we set the gradient of the error function $\\nabla E(t)$ to zero:\n",
    "\n",
    "$$\\nabla E(t) = \\frac{\\partial E}{\\partial t} = 0$$\n",
    "\n",
    "Performing the derivative, we find:\n",
    "\n",
    "$$\\nabla E(t) = \\frac{1}{N}\\sum_{i=1}^N  -2(q_i -Rp_i -t)$$\n",
    "\n",
    "This equation can be simplified further:\n",
    "\n",
    "$$\\nabla E(t) = 2\\left(R\\sum_{i=1}^N\\frac{p_i}{N} + \\sum_{i=1}^N\\frac{t}{N} - \\sum_{i=1}^N\\frac{q_i}{N}\\right)$$\n",
    "\n",
    "Which simplifies to:\n",
    "\n",
    "$$\\nabla E(t) = 2(R\\mu_P+ t - \\mu_Q)$$\n",
    "\n",
    "Solving for $t$ where $\\nabla E(t)=0$:\n",
    "\n",
    "$$ t = \\mu_Q - R\\mu_P$$\n",
    "\n",
    "\n",
    "#### Solving for R\n",
    "\n",
    "After substituting tt back into the original error function, we refine the equation:\n",
    "\n",
    "$$E(R) = \\frac{1}{N}\\sum_{i=1}^N  || q_i - (Rp_i + \\mu_Q - R\\mu_P)||^2$$\n",
    "\n",
    "Reformulating the error expression:\n",
    "\n",
    "$$E(R) = \\frac{1}{N}\\sum_{i=1}^N  || (q_i - \\mu_Q) - R(p_i - \\mu_P)||^2$$\n",
    "\n",
    "If we focus on the terms $(q_i - \\mu_Q)$ and $(p_i - \\mu_P)$ these can be recognized as the coordinates of the points re-centered at the origin, denoted as $q_i^c$ and $p_i^c$ respectively: \n",
    "\n",
    "$$\n",
    "p_i^c = (p_i - \\mu_P) \n",
    "$$\n",
    "$$\n",
    "q_i^c = (q_i - \\mu_P) \n",
    "$$\n",
    "\n",
    "Given the re-centered coordinates $p_i^c$​ and $q_i^c$, the error function can be effectively represented as the alignment error between these centered point sets. This allows us to rewrite the error function as follows:\n",
    "\n",
    "$$E(R) = \\frac{1}{N}\\sum_{i=1}^N  || q_i^c  - Rp_i^c||^2 =  \\frac{1}{N}\\sum_{i=1}^N ( q_i^{cT} q_i^c  -2q_i^{cT} Rp_i^c + p_i^{cT} p_i^c )$$\n",
    "\n",
    "Since the terms $q_i^{cT} q_i^c $ and $p_i^{cT} p_i^c $, are constants with respect to $R$, we focus on minimizing $-2q_i^{c^T} Rp_i^c$. This lead us to reformulate the optimization problem as:\n",
    "\n",
    "$$ \n",
    "    \\operatorname*{arg\\,min}_{R} E(R) = \\operatorname*{arg\\,min}_{R}(-\\sum_{i=1}^Nq_i^{cT} Rp_i^c)\n",
    "$$\n",
    "\n",
    "To facilitate the computation, let us denote matrices $\\mathbf{X}$ and $\\mathbf{Y}$ that consist of all centered points $p_i^c$, $q_i^c$ respectively: \n",
    "\n",
    "$$\\mathbf{X} = [p_0^c, \\cdots, p_i^c, \\cdots, p_N^c]$$\n",
    "$$\\mathbf{Y} = [q_0^c, \\cdots, q_i^c, \\cdots, q_N^c]$$\n",
    "\n",
    "\n",
    "Considering the matrix product $\\mathbf{A}=\\mathbf{Y}^T\\mathbf{R}\\mathbf{X}$, we find:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "        q_0^cRp_0^c & \\cdots & q_0^cRp_i^c & \\cdots & q_0^cRp_N^c \\\\\n",
    "        \\vdots & \\ddots & \\vdots & & \\vdots \\\\\n",
    "        q_i^c & \\cdots & q_i^cRp_i^c & \\cdots & q_0^cRp_N^c \\\\\n",
    "        \\vdots& & \\vdots& \\ddots & \\vdots\\\\\n",
    "        q_N^c & \\cdots & q_N^cRp_i^c & \\cdots & q_N^cRp_N^c \n",
    "    \\end{bmatrix} \n",
    "$$\n",
    "\n",
    "Therefore sum $\\sum_{i=1}^Nq_i^{cT} Rp_i^c$ is the trace of matrix $\\mathbf{A}$. The trace of a matrix, $\\text{Tr}⁡(\\mathbf{A})$, being the sum of diagonal elements of a matrix, simplifies the expresion of this sum. This reduction is particularly useful because maximizing the trace $\\text{Tr}⁡(\\mathbf{A})$ is equivalent to minimizing $-\\sum_{i=1}^Nq_i^{cT} Rp_i^c$​, which aligns with our original problem.\n",
    "\n",
    "**Trace Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define two sets of 2D points (for simplicity)\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]]).T  # Source points in columns\n",
    "Y = np.array([[2, 3], [4, 5], [6, 7], [8, 9]]).T  # Target points in columns\n",
    "\n",
    "# Define a rotation matrix using yaw angle (45 degrees) for 2D rotation\n",
    "yaw = np.radians(45)  # Convert degrees to radians\n",
    "R_matrix = np.array([\n",
    "    [np.cos(yaw), -np.sin(yaw)],\n",
    "    [np.sin(yaw),  np.cos(yaw)]\n",
    "])\n",
    "\n",
    "# Apply rotation\n",
    "A = Y.T @ R_matrix @ X\n",
    "\n",
    "# Calculate the trace of the matrix A\n",
    "trace_A = np.trace(A)\n",
    "\n",
    "# Calculate the trace manually (only works if A.shape[0] == A.shape[1])\n",
    "diagonal_sum = sum(A[i, i] for i in range(A.shape[0]))\n",
    "\n",
    "print(f\"The trace of matrix A is: {trace_A}\")\n",
    "print(f\"The sum of the diagonal of A is: {diagonal_sum}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the properties of the trace function states:\n",
    "\n",
    "$$\\text{Tr}⁡(\\mathbf{AB}) = \\text{Tr}⁡(\\mathbf{BA}) $$\n",
    "\n",
    "Therefore, for the matrices involved in our SVD optimization problem:\n",
    "\n",
    "$$\\text{Tr}⁡(\\mathbf{Y}^T\\mathbf{R}\\mathbf{X}) = \\text{Tr}⁡(\\mathbf{R}\\mathbf{X}\\mathbf{Y}^T) $$\n",
    "\n",
    "Consider $\\mathbf{X}\\mathbf{Y}^T$, this matrix represents the **cross covariance** matrix $\\mathbf{S}$ between $Q$ and $P$. Knowing this cross-covariance we can compute its SVD decomposition:\n",
    "\n",
    "$$\n",
    "\\mathrm{SVD}(\\mathbf{S}) = U\\Sigma V^T\n",
    "$$\n",
    "\n",
    "Then the trace can be written as:\n",
    "\n",
    "$$\n",
    "  \\text{Tr}⁡(\\mathbf{R}\\mathbf{X}\\mathbf{Y}^T) = \n",
    "  \\text{Tr}⁡(\\mathbf{R}U\\Sigma V^T) = \n",
    "  \\text{Tr}⁡(\\Sigma V^T\\mathbf{R}U)  \n",
    "$$\n",
    "\n",
    "Where, $\\Sigma$ is a diagonal matrix, and $V^T$ and $U$ are orthogonal matrices. In the context of SVD, $V^T$ and $U$ perform rotations without altering the scale of the data, whereas the scaling effect is exclusively governed by $\\Sigma$, which is a diagonal matrix containing the singular values. Consequently, the trace is maximized when $\\text{Tr}⁡(\\Sigma V^T\\mathbf{R}U) = \\text{Tr}⁡(\\Sigma)$. In simpler terms, the trace attains its maximum value when the rotation matrices ($V^T$ and $U$) align the data in such a way that the scaling factors provided by $\\Sigma$ are fully utilized.\n",
    "\n",
    "$$\n",
    "   V^T\\mathbf{R}U = I\n",
    "$$\n",
    "\n",
    "Finally:\n",
    "\n",
    "$$\n",
    "  \\mathbf{R} = VU^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "source": [
    "def align_svd_known_correspondences(source_points: np.ndarray, target_points: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Aligns two sets of 3D points using the method of Singular Value Decomposition (SVD) based on known correspondences.\n",
    "    \n",
    "    Parameters:\n",
    "    - source_points (np.ndarray): The source points as an Nx3 numpy array.\n",
    "    - target_points (np.ndarray): The target points as an Nx3 numpy array.\n",
    "    \n",
    "    Returns:\n",
    "    - Tuple[np.ndarray, np.ndarray]: A tuple containing the rotation matrix and the translation vector.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate inputs\n",
    "    if not (isinstance(source_points, np.ndarray) and isinstance(target_points, np.ndarray)):\n",
    "        raise ValueError(\"Both source_points and target_points must be numpy arrays.\")\n",
    "    if source_points.ndim != 2 or target_points.ndim != 2:\n",
    "        raise ValueError(\"Both source_points and target_points must be 2-dimensional.\")\n",
    "    if source_points.shape[1] != 3 or target_points.shape[1] != 3:\n",
    "        raise ValueError(\"Both source_points and target_points must have three columns (3D points).\")\n",
    "    if source_points.shape[0] != target_points.shape[0]:\n",
    "        raise ValueError(\"Both source_points and target_points must have the same number of rows (correspondences).\")\n",
    "    \n",
    "\n",
    "    # Calculate centroids of the source and target points\n",
    "    centroid_source = calculate_centroid(source_points)\n",
    "    centroid_target = calculate_centroid(target_points)\n",
    "    \n",
    "    # Center the points around the centroid\n",
    "    centered_source = source_points - centroid_source\n",
    "    centered_target = target_points - centroid_target\n",
    "    \n",
    "    # Compute the covariance matrix from the centered coordinates\n",
    "    S = centered_source.T @ centered_target\n",
    "    \n",
    "    # Perform Singular Value Decomposition\n",
    "    U, _, V = np.linalg.svd(S)\n",
    "    \n",
    "    # Compute the rotation matrix, ensuring a right-handed coordinate system\n",
    "    R = V.T @ U.T\n",
    "\n",
    "    if np.linalg.det(R) < 0:\n",
    "        V[2, :] *= -1\n",
    "        R = V.T @ U.T\n",
    "    \n",
    "    # Compute the translation vector\n",
    "    tr = centroid_target - R @ centroid_source\n",
    "    \n",
    "    return R, tr[:, np.newaxis]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "source": [
    "# Load points from a file\n",
    "Q = utils.pcd_from_path(\"./dataset/arrow.pcd\")\n",
    "\n",
    "# Create rigid transformation parameters\n",
    "t = np.array([[10], [5], [0]])  # Translation vector\n",
    "\n",
    "# Rotation matrix using Roll, Pitch, Yaw (only yaw is non-zero for 2D rotation around Z)\n",
    "yaw = 45  # 45 degrees over z axis\n",
    "R = Rotation.from_euler('z', yaw, degrees=True).as_matrix()\n",
    "\n",
    "# Apply transformation\n",
    "P = rigid_transformation(Q, R, t)\n",
    "\n",
    "# Calculate Rotation and Translation from P perspective\n",
    "R_estimated, t_estimated = align_svd_known_correspondences(P, Q)\n",
    "\n",
    "# Apply new transformation\n",
    "P_transformed = rigid_transformation(P, R_estimated, t_estimated)\n",
    "\n",
    "# Plotting the original and transformed point cloud\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot first initial problem\n",
    "ax1.scatter(P[:,0], P[:,1], color='red', alpha=0.5, label='Source Points')\n",
    "ax1.scatter(Q[:,0], Q[:,1], color='green', alpha=0.5, label='Target Points')\n",
    "ax1.set_xlabel('X coordinate')\n",
    "ax1.set_ylabel('Y coordinate')\n",
    "ax1.set_title('Points without alignment')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot points after finding transformation\n",
    "ax2.scatter(Q[:,0], Q[:,1], color='green', alpha=0.5, label='Target Points')\n",
    "ax2.scatter(P_transformed[:,0], P_transformed[:,1], color='blue', alpha=0.3, label='Source Points Transformed')\n",
    "ax2.set_xlabel('X coordinate')\n",
    "ax2.set_ylabel('Y coordinate')\n",
    "ax2.set_title('Aligned points')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correspondences\n",
    "\n",
    "### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous discussions, we examined the mathematical formulations for determining the transformation between reference systems of one point cloud to another using Least Square Optimization via SVD. However, these formulations assumed that we know the corresponding indices, indicating which points in $P$ match the points in $Q$. We initially assumed that the indices were identical.\n",
    "\n",
    "When the indices are not identical, the covariance matrix $\\mathbf{S}$ becomes indeterminate. This is because using $\\mathbf{X}\\mathbf{Y}^T$ does not accurately reflect the variance of points from the source relative to the target when the points do not align correctly.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Let’s see what happens if we use the previous function when we shuffle the points in the point set $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "source": [
    "# Load points from a file\n",
    "Q = utils.pcd_from_path(\"./dataset/arrow.pcd\")\n",
    "\n",
    "# Create rigid transformation parameters\n",
    "t = np.array([[10], [5], [0]])  # Translation vector\n",
    "\n",
    "# Rotation matrix using Roll, Pitch, Yaw (only yaw is non-zero for 2D rotation around Z)\n",
    "yaw = 45  # 45 degrees over z axis\n",
    "R = Rotation.from_euler('z', yaw, degrees=True).as_matrix()\n",
    "\n",
    "# Apply transformation\n",
    "P = rigid_transformation(Q, R, t)\n",
    "\n",
    "# Shuffle points\n",
    "rng = np.random.default_rng()\n",
    "rng.shuffle(P, axis=0)\n",
    "\n",
    "# Calculate Rotation and Translation from P perspective\n",
    "R_estimated, t_estimated = align_svd_known_correspondences(P, Q)\n",
    "\n",
    "# Apply new transformation\n",
    "P_transformed = rigid_transformation(P, R_estimated, t_estimated)\n",
    "\n",
    "# Plotting the original and transformed point cloud\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot first initial problem\n",
    "ax1.scatter(P[:,0], P[:,1], color='red', alpha=0.5, label='Source Points')\n",
    "ax1.scatter(Q[:,0], Q[:,1], color='green', alpha=0.5, label='Target Points')\n",
    "ax1.set_xlabel('X coordinate')\n",
    "ax1.set_ylabel('Y coordinate')\n",
    "ax1.set_title('Points without alignment')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot points after finding transformation\n",
    "ax2.scatter(Q[:,0], Q[:,1], color='green', alpha=0.5, label='Target Points')\n",
    "ax2.scatter(P_transformed[:,0], P_transformed[:,1], color='blue', alpha=0.3, label='Source Points Transformed')\n",
    "ax2.set_xlabel('X coordinate')\n",
    "ax2.set_ylabel('Y coordinate')\n",
    "ax2.set_title('Aligned points')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe, the points do not align correctly because the rotation is incorrect. You can execute the previous cell multiple times to see how the algorithm fails to converge to a specific solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Neighrest Neighbor\n",
    "\n",
    "Since it's necessary to determine correspondences between the indices of $P$ and $Q$, where:\n",
    "\n",
    "$$ (i,j) : q_j = \\mathbf{R}p_i+t$$\n",
    "\n",
    "We can use a nearest neighbor approach to find the pairs $(i,j)$. Point $p_i$​ from the source points $P$ corresponds to point $q_j$​ from the target points $Q$. However, computing all distances directly between every point in $P$ and $Q$ is computationally intensive. Thus, to efficiently solve this problem, we can utilize a **K-Dimensional Tree (KD-Tree)**.\n",
    "\n",
    "A KD-Tree is a binary search tree that organizes multi-dimensional data hierarchically, enabling quick nearest-neighbor searches. Each node splits the space along an axis, alternating between dimensions at each level. This hierarchical organization allows the KD-Tree to prune irrelevant branches, speeding up nearest neighbor queries.\n",
    "\n",
    "**Example of Using a KD-Tree for Correspondence:**\n",
    "\n",
    "1. **Build the KD-Tree:** Organize the **centered** target point clouds into a KD-Tree.\n",
    "2. **Query for Correspondences:** For each **centered** source point in $P$, search the KD-Tree to find the nearest neighbor within a specified radius.\n",
    "3. **Handle No Match:** If no neighbor is found within the maximum radius, the source point is considered unassociated.\n",
    "\n",
    "Let's examine how to establish these correspondences for a set of source points $P$ and target points $Q$ in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "def get_correspondences(source_points:np.ndarray, target_points: np.ndarray, max_dist : float =10):\n",
    "    # Validate inputs\n",
    "    if not (isinstance(source_points, np.ndarray) and isinstance(target_points, np.ndarray)):\n",
    "        raise ValueError(\"Both source_points and target_points must be numpy arrays.\")\n",
    "    if source_points.ndim != 2 or target_points.ndim != 2:\n",
    "        raise ValueError(\"Both source_points and target_points must be 2-dimensional.\")\n",
    "    if source_points.shape[1] != 3 or target_points.shape[1] != 3:\n",
    "        raise ValueError(\"Both source_points and target_points must have three columns (3D points).\")\n",
    "    if source_points.shape[0] != target_points.shape[0]:\n",
    "        raise ValueError(\"Both source_points and target_points must have the same number of rows (correspondences).\")\n",
    "    \n",
    "    centroid_source = calculate_centroid(source_points)\n",
    "    centroid_traget = calculate_centroid(target_points)\n",
    "\n",
    "    centered_source = source_points - centroid_source\n",
    "    centered_target = target_points - centroid_traget\n",
    "    \n",
    "    # build KDTree\n",
    "    tree = KDTree(centered_target)\n",
    "\n",
    "    # Find nearest neighbors\n",
    "    distances, indices = tree.query(centered_source)\n",
    "    \n",
    "    # Compute correspondences\n",
    "    correspondences = np.asarray([(i, j) for i, j in enumerate(indices)])\n",
    "    \n",
    "    # Filter correspondences\n",
    "    mask = distances < max_dist\n",
    "    correspondences = correspondences[mask, :]\n",
    "    \n",
    "    return correspondences"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "source": [
    "# Load points from a file\n",
    "Q = utils.pcd_from_path(\"./dataset/arrow.pcd\")\n",
    "\n",
    "# Create rigid transformation parameters\n",
    "t = np.array([[10], [5], [0]])  # Translation vector\n",
    "\n",
    "# Rotation matrix using Roll, Pitch, Yaw (only yaw is non-zero for 2D rotation around Z)\n",
    "yaw = 45  # 45 degrees over z axis\n",
    "R = Rotation.from_euler('z', yaw, degrees=True).as_matrix()\n",
    "\n",
    "# Apply transformation\n",
    "P = rigid_transformation(Q, R, t)\n",
    "\n",
    "# Shuffle points\n",
    "rng = np.random.default_rng()\n",
    "rng.shuffle(P, axis=0)\n",
    "\n",
    "correspondences = get_correspondences(P, Q)\n",
    "\n",
    "\n",
    "# Plotting the original and transformed point cloud\n",
    "plt.figure()\n",
    "\n",
    "# Plot first initial problem\n",
    "plt.scatter(P[:,0], P[:,1], color='red', alpha=0.5, label='Source Points')\n",
    "plt.scatter(Q[:,0], Q[:,1], color='green', alpha=0.5, label='Target Points')\n",
    "\n",
    "# Plot correspondences\n",
    "label = \"Correspondences\"\n",
    "for i,j in correspondences:\n",
    "    plt.plot([P[i,0], Q[j,0]], [P[i,1], Q[j,1]], 'grey', lw=0.5, label=label)\n",
    "    label = ''\n",
    "\n",
    "# Plot params\n",
    "plt.xlabel('X coordinate')\n",
    "plt.ylabel('Y coordinate')\n",
    "plt.title('Points without alignment')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we use this algorithm to align two point clouds, taking advantage of SVD with nearest-neighbor correspondences identified via KD-Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "source": [
    "def align_svd_one_iteration(source_points: np.ndarray, target_points: np.ndarray, max_dist: float = 10) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Aligns two sets of 3D points using the method of Singular Value Decomposition (SVD) based on known correspondences.\n",
    "    \n",
    "    Parameters:\n",
    "    - source_points (np.ndarray): The source points as an Nx3 numpy array.\n",
    "    - target_points (np.ndarray): The target points as an Nx3 numpy array.\n",
    "    \n",
    "    Returns:\n",
    "    - Tuple[np.ndarray, np.ndarray]: A tuple containing the rotation matrix and the translation vector.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate inputs\n",
    "    if not (isinstance(source_points, np.ndarray) and isinstance(target_points, np.ndarray)):\n",
    "        raise ValueError(\"Both source_points and target_points must be numpy arrays.\")\n",
    "    if source_points.ndim != 2 or target_points.ndim != 2:\n",
    "        raise ValueError(\"Both source_points and target_points must be 2-dimensional.\")\n",
    "    if source_points.shape[1] != 3 or target_points.shape[1] != 3:\n",
    "        raise ValueError(\"Both source_points and target_points must have three columns (3D points).\")\n",
    "    if source_points.shape[0] != target_points.shape[0]:\n",
    "        raise ValueError(\"Both source_points and target_points must have the same number of rows (correspondences).\")\n",
    "    \n",
    "\n",
    "    # Calculate centroids of the source and target points\n",
    "    centroid_source = calculate_centroid(source_points)\n",
    "    centroid_target = calculate_centroid(target_points)\n",
    "    \n",
    "    # Center the points around the centroid\n",
    "    centered_source = source_points - centroid_source\n",
    "    centered_target = target_points - centroid_target\n",
    "    \n",
    "    # Build KDTree\n",
    "    tree = KDTree(centered_target)\n",
    "\n",
    "    # Find nearest neighbors\n",
    "    distances, indices = tree.query(centered_source)\n",
    "    \n",
    "    # Compute correspondences\n",
    "    correspondences = np.asarray([(i, j) for i, j in enumerate(indices)])\n",
    "    \n",
    "    # Filter correspondences\n",
    "    mask = distances < max_dist\n",
    "    correspondences = correspondences[mask, :]\n",
    "\n",
    "    # Sort acording to correspondences\n",
    "    sorted_source = centered_source[correspondences[:, 0]]\n",
    "    sorted_target = centered_target[correspondences[:, 1]]\n",
    "\n",
    "    # Compute the covariance matrix from the centered coordinates\n",
    "    S = sorted_source.T @ sorted_target\n",
    "    \n",
    "    # Perform Singular Value Decomposition\n",
    "    U, _, V = np.linalg.svd(S)\n",
    "    \n",
    "    # Compute the rotation matrix, ensuring a right-handed coordinate system\n",
    "    R = V.T @ U.T\n",
    "\n",
    "    if np.linalg.det(R) < 0:\n",
    "        V[2, :] *= -1\n",
    "        R = V.T @ U.T\n",
    "    \n",
    "    # Compute the translation vector\n",
    "    tr = centroid_target - R @ centroid_source\n",
    "    \n",
    "    return R, tr[:, np.newaxis], correspondences"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "source": [
    "# Load points from a file\n",
    "Q = utils.pcd_from_path(\"./dataset/arrow.pcd\")\n",
    "\n",
    "# Create rigid transformation parameters\n",
    "t = np.array([[10], [5], [0]])  # Translation vector\n",
    "\n",
    "# Rotation matrix using Roll, Pitch, Yaw (only yaw is non-zero for 2D rotation around Z)\n",
    "yaw = 45  # 45 degrees over z axis\n",
    "R = Rotation.from_euler('z', yaw, degrees=True).as_matrix()\n",
    "\n",
    "# Apply transformation\n",
    "P = rigid_transformation(Q, R, t)\n",
    "\n",
    "# Shuffle points\n",
    "rng = np.random.default_rng()\n",
    "rng.shuffle(P, axis=0)\n",
    "\n",
    "# Calculate Rotation and Translation from P perspective\n",
    "R_estimated, t_estimated, correspondences = align_svd_one_iteration(P, Q)\n",
    "\n",
    "# Apply new transformation\n",
    "P_transformed = rigid_transformation(P, R_estimated, t_estimated)\n",
    "\n",
    "# Plotting the original and transformed point cloud\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot first initial problem\n",
    "ax1.scatter(P[:,0], P[:,1], color='red', alpha=0.5, label='Source Points')\n",
    "ax1.scatter(Q[:,0], Q[:,1], color='green', alpha=0.5, label='Target Points')\n",
    "\n",
    "# Plot correspondences\n",
    "label = \"Correspondences\"\n",
    "for i,j in correspondences:\n",
    "    ax1.plot([P[i,0], Q[j,0]], [P[i,1], Q[j,1]], 'grey', lw=0.5, label=label)\n",
    "    label = ''\n",
    "\n",
    "ax1.set_xlabel('X coordinate')\n",
    "ax1.set_ylabel('Y coordinate')\n",
    "ax1.set_title('Points without alignment')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot points after finding transformation\n",
    "ax2.scatter(Q[:,0], Q[:,1], color='green', alpha=0.5, label='Target Points')\n",
    "ax2.scatter(P_transformed[:,0], P_transformed[:,1], color='blue', alpha=0.3, label='Source Points Transformed')\n",
    "ax2.set_xlabel('X coordinate')\n",
    "ax2.set_ylabel('Y coordinate')\n",
    "ax2.set_title('Aligned points')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm demonstrates stability regardless of point ordering, consistently reaching a local solution. However, it fails to achieve a global solution due to two primary issues:\n",
    "\n",
    "1. **Multiple Source Points Matching a Single Target Point:** Several source points mapping to the same target point can lead to distortions from ambiguous associations, where nearest neighbor searches assign multiple source points to a single target point without discrimination.\n",
    "\n",
    "2. **Unmatched Source Points:** Some source points do not find corresponding targets, likely due to occlusion, noise, or regions where the point clouds do not overlap. These unmatched points can disrupt the overall alignment accuracy.\n",
    "\n",
    "Despite these initial challenges, the alignment process can serve as the foundational step in a more comprehensive approach to solving the global alignment problem. This initial solution, often considered the first iteration in the Iterative Closest Point algorithm, sets the stage for further refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteratice Closest Point Algorithm\n",
    "\n",
    "The Iterative Closest Point (ICP) algorithm is an iterative process that aims to refine the initial alignment to reach a globally optimal solution. In each iteration, the previously computed transformation is used to transform the source point cloud, reducing the distance between the source and target points. This process is repeated until the rotation matrix ($R_n$) and translation vector ($t_n$) at iteration  $n$ converge to identity and zero, respectively, or until a maximum number of iterations is reached.\n",
    "\n",
    "\n",
    "### Algorithm Steps\n",
    "\n",
    "1. **Initial Alignment:** The source and target point clouds are pre-aligned based on an initial guess or a rough estimation. This can be derived from prior knowledge or a previous state in a sequence.\n",
    "\n",
    "2. **Nearest Neighbor Search:** For each point in the source point cloud, find the closest point in the target point cloud. This step is crucial and can significantly affect the performance and outcome of the algorithm.\n",
    "\n",
    "3. **Correspondence Matching:** Pair each point from the source with its closest point found in the target. These pairs are considered as correspondences.\n",
    "\n",
    "4. **Transformation Estimation:** Compute the optimal rigid transformation (rotation and translation) that minimizes the distances between matched pairs. This is typically done using Singular Value Decomposition (SVD) or a similar method to solve the least squares problem.\n",
    "\n",
    "5. **Transformation:** Apply the computed transformation to the source points, bringing them closer to the target points.\n",
    "\n",
    "6. Accumulate Transformation: Update the accumulated transformation:\n",
    "    $$\\mathbf{R} \\rightarrow \\mathbf{R} \\times \\mathbf{R}_n $$\n",
    "    $$t \\rightarrow \\mathbf{R_n} t +  t_n $$\n",
    "\n",
    "7. **Iteration:** Repeat steps 2 through 5 until convergence criteria are met. Convergence can be determined by a small change in the error metric or a fixed number of iterations.\n",
    "\n",
    "8. **Final Alignment:** Once converged, the source points should be optimally aligned to the target points under the computed transformation\n",
    "\n",
    "### Implementation\n",
    "\n",
    "Below is a Python implementation of the ICP using SVD for transformation estimation and a KD-Tree for efficient nearest neighbor searches. This example shows how to apply the ICP algorithm to align 2D point clouds iteratively:\n",
    "\n",
    "#### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "source": [
    "def align_svd(source_points: np.ndarray, target_points: np.ndarray, max_dist: float = 100, max_iter: int=100, tol=1e-5) -> np.ndarray:\n",
    "    \n",
    "    # Calculate centroids of the source and target points\n",
    "    centroid_target = calculate_centroid(target_points)\n",
    "\n",
    "    # Center the points around the centroid\n",
    "    centered_target = target_points - centroid_target\n",
    "    \n",
    "    # Build KDTree\n",
    "    tree = KDTree(centered_target)\n",
    "\n",
    "    # Initilialize R and t\n",
    "    R = np.eye(target_points.shape[1])\n",
    "    t = np.zeros((target_points.shape[1], 1))\n",
    "\n",
    "    R_list = [R]\n",
    "    t_list = [t]\n",
    "    corres_values_list = []\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        # Center source\n",
    "        centroid_source = calculate_centroid(source_points)\n",
    "        centered_source = source_points - centroid_source\n",
    "\n",
    "        # Find nearest neighbors\n",
    "        distances, indices = tree.query(centered_source)\n",
    "        # Compute correspondences\n",
    "        correspondences = np.asarray([(i, j) for i, j in enumerate(indices)])\n",
    "\n",
    "        mask = distances < max_dist\n",
    "        \n",
    "        # Filter correspondences\n",
    "        correspondences = correspondences[mask, :]\n",
    "        \n",
    "        # Sort points\n",
    "        sorted_source = centered_source[correspondences[:, 0]]\n",
    "        sorted_target = centered_target[correspondences[:, 1]]\n",
    "\n",
    "        #  Compute covariance matrix\n",
    "        S = sorted_source.T @ sorted_target\n",
    "    \n",
    "        # Perform Singular Value Decomposition\n",
    "        U, _, V = np.linalg.svd(S)\n",
    "        \n",
    "        # Compute the rotation matrix, ensuring a right-handed coordinate system\n",
    "        Rn = V.T @ U.T\n",
    "\n",
    "        # Compute the translation vector\n",
    "        tn = centroid_target - Rn @ centroid_source\n",
    "        tn = tn[:,np.newaxis]\n",
    "        source_points = rigid_transformation(source_points, Rn, tn)\n",
    "        \n",
    "        # Update transformation\n",
    "        t = Rn @ t + tn\n",
    "        R = np.dot(R, Rn)\n",
    "        \n",
    "        t_list.append(t.copy())\n",
    "        R_list.append(R.copy())\n",
    "        corres_values_list.append(correspondences.copy())\n",
    "\n",
    "        if np.allclose(tn, 0, atol=tol) and np.allclose(Rn, np.eye(Rn.shape[0]), atol=tol):\n",
    "            break\n",
    "\n",
    "    return R, t, R_list, t_list, corres_values_list"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "source": [
    "# Load points from a file\n",
    "Q = utils.pcd_from_path(\"./dataset/arrow.pcd\")\n",
    "\n",
    "# Create rigid transformation parameters\n",
    "t = np.array([[10], [5], [0]])  # Translation vector\n",
    "\n",
    "# Rotation matrix using Roll, Pitch, Yaw (only yaw is non-zero for 2D rotation around Z)\n",
    "yaw = 45  # 45 degrees over z axis\n",
    "R = Rotation.from_euler('z', yaw, degrees=True).as_matrix()\n",
    "\n",
    "# Apply transformation\n",
    "P = rigid_transformation(Q, R, t)\n",
    "\n",
    "# Shuffle points\n",
    "rng = np.random.default_rng()\n",
    "rng.shuffle(P, axis=0)\n",
    "\n",
    "# Calculate Rotation and Translation from P perspective\n",
    "R_estimated, t_estimated, R_list, t_list, corres_list = align_svd(P, Q, max_dist=1)\n",
    "\n",
    "# Animate result\n",
    "utils.animate_icp_results(P,Q, R_list, t_list, corres_list)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load points from a file\n",
    "P = utils.pcd_from_path(\"./dataset/source.pcd\")\n",
    "Q = utils.pcd_from_path(\"./dataset/target.pcd\")\n",
    "\n",
    "# Calculate Rotation and Translation from P perspective\n",
    "R_estimated, t_estimated, R_list, t_list, corres_list = align_svd(P, Q, max_dist=1)\n",
    "\n",
    "# Animate result\n",
    "utils.animate_icp_results(P,Q, R_list, t_list, corres_list)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "metadata": {}
   },
   "source": [
    "## ICP Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided you with an ICP class that you can use for aligning pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from tools.ICP import ICP\n",
    "\n",
    "# Load points from a file\n",
    "Q = utils.pcd_from_path(\"./dataset/arrow.pcd\")\n",
    "\n",
    "# Create rigid transformation parameters\n",
    "t = np.array([[10], [5], [0]])  # Translation vector\n",
    "\n",
    "# Rotation matrix using Roll, Pitch, Yaw (only yaw is non-zero for 2D rotation around Z)\n",
    "yaw = 45  # 45 degrees over z axis\n",
    "R = Rotation.from_euler('z', yaw, degrees=True).as_matrix()\n",
    "\n",
    "# Apply transformation\n",
    "P = rigid_transformation(Q, R, t)\n",
    "\n",
    "# Shuffle points\n",
    "rng = np.random.default_rng()\n",
    "rng.shuffle(P, axis=0)\n",
    "\n",
    "# Create ICP object\n",
    "icp = ICP(max_dist=100)\n",
    "\n",
    "# Apply aligment\n",
    "R_estimated, t_estimated, R_list, t_list, corres_list = icp.align(P,Q)\n",
    "\n",
    "# Animate result\n",
    "utils.animate_icp_results(P,Q, R_list, t_list, corres_list)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load points from a file\n",
    "P = utils.pcd_from_path(\"./dataset/source.pcd\")\n",
    "Q = utils.pcd_from_path(\"./dataset/target.pcd\")\n",
    "\n",
    "# Apply aligment\n",
    "R_estimated, t_estimated, R_list, t_list, corres_list = icp.align(P,Q)\n",
    "\n",
    "# Animate result\n",
    "utils.animate_icp_results(P,Q, R_list, t_list, corres_list)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
